{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2977da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install yomitoku fastapi uvicorn pyngrok nest-asyncio python-multipart\n",
    "\n",
    "import nest_asyncio\n",
    "from fastapi import FastAPI, HTTPException, File, UploadFile\n",
    "import uvicorn\n",
    "import asyncio\n",
    "from PIL import Image, ImageOps\n",
    "import io\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tempfile\n",
    "import sys\n",
    "\n",
    "# Colab環境チェック\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# ライブラリインポート\n",
    "try:\n",
    "    from yomitoku.document_analyzer import DocumentAnalyzer\n",
    "    from yomitoku.data.functions import load_pdf\n",
    "    from pyngrok import ngrok, conf\n",
    "except ImportError as e:\n",
    "    print(f\"ライブラリが見つかりません: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# OCRエンジンの初期化\n",
    "try:\n",
    "    warnings.filterwarnings('ignore', category=UserWarning, module='onnxruntime')\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    analyzer = DocumentAnalyzer(device=device)\n",
    "except Exception as e:\n",
    "    print(f\"DocumentAnalyzerの初期化に失敗しました: {e}\")\n",
    "    analyzer = None\n",
    "\n",
    "def extract_text_preserving_layout(results):\n",
    "    if not results:\n",
    "        return \"\"\n",
    "\n",
    "    elements = []\n",
    "    source_list = []\n",
    "    if hasattr(results, \"lines\") and results.lines:\n",
    "        source_list = results.lines\n",
    "    elif hasattr(results, \"paragraphs\") and results.paragraphs:\n",
    "        source_list = results.paragraphs\n",
    "    else:\n",
    "        return str(results)\n",
    "\n",
    "    for item in source_list:\n",
    "        text = \"\"\n",
    "        box = None\n",
    "        if hasattr(item, \"content\"): text = item.content\n",
    "        elif hasattr(item, \"contents\"): text = item.contents\n",
    "        elif hasattr(item, \"text\"): text = item.text\n",
    "\n",
    "        if hasattr(item, \"box\"):\n",
    "            box = item.box\n",
    "        elif hasattr(item, \"points\"):\n",
    "            pts = np.array(item.points)\n",
    "            if pts.size > 0:\n",
    "                box = [np.min(pts[:, 0]), np.min(pts[:, 1]), np.max(pts[:, 0]), np.max(pts[:, 1])]\n",
    "\n",
    "        if text and box is not None:\n",
    "            try:\n",
    "                center_y = (box[1] + box[3]) / 2\n",
    "                height = box[3] - box[1]\n",
    "                elements.append({\"text\": text, \"box\": box, \"cy\": center_y, \"h\": height, \"x\": box[0]})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not elements:\n",
    "        return \"\"\n",
    "\n",
    "    elements.sort(key=lambda e: e[\"cy\"])\n",
    "    merged_lines = []\n",
    "    current_line_elements = []\n",
    "\n",
    "    for e in elements:\n",
    "        if not current_line_elements:\n",
    "            current_line_elements.append(e)\n",
    "            continue\n",
    "\n",
    "        last_e = current_line_elements[-1]\n",
    "        if abs(e[\"cy\"] - last_e[\"cy\"]) < (last_e[\"h\"] * 0.6):\n",
    "            current_line_elements.append(e)\n",
    "        else:\n",
    "            current_line_elements.sort(key=lambda x: x[\"x\"])\n",
    "            line_str = \"  \".join([el[\"text\"] for el in current_line_elements])\n",
    "            merged_lines.append(line_str)\n",
    "            current_line_elements = [e]\n",
    "\n",
    "    if current_line_elements:\n",
    "        current_line_elements.sort(key=lambda x: x[\"x\"])\n",
    "        line_str = \"  \".join([el[\"text\"] for el in current_line_elements])\n",
    "        merged_lines.append(line_str)\n",
    "\n",
    "    return \"\\n\".join(merged_lines)\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Yomitoku API is running\"}\n",
    "\n",
    "@app.post(\"/ocr\")\n",
    "async def run_ocr(file: UploadFile = File(...)):\n",
    "    if analyzer is None:\n",
    "        raise HTTPException(status_code=503, detail=\"OCR Not Initialized\")\n",
    "\n",
    "    try:\n",
    "        image_bytes = await file.read()\n",
    "        all_ocr_text = \"\"\n",
    "\n",
    "        if file.content_type == \"application/pdf\":\n",
    "            with tempfile.NamedTemporaryFile(delete=True, suffix=\".pdf\") as temp_pdf:\n",
    "                temp_pdf.write(image_bytes)\n",
    "                temp_pdf.flush()\n",
    "                imgs = load_pdf(temp_pdf.name)\n",
    "\n",
    "            if not imgs:\n",
    "                raise HTTPException(status_code=400, detail=\"PDF Error\")\n",
    "\n",
    "            loop = asyncio.get_event_loop()\n",
    "            page_texts = []\n",
    "            for img in imgs:\n",
    "                results, _, _ = await loop.run_in_executor(None, analyzer, img)\n",
    "                page_texts.append(extract_text_preserving_layout(results))\n",
    "            all_ocr_text = \"\\n\\n\".join(page_texts)\n",
    "\n",
    "        else:\n",
    "            pil_image = Image.open(io.BytesIO(image_bytes))\n",
    "            pil_image = ImageOps.exif_transpose(pil_image)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "            img = np.array(pil_image)[:, :, ::-1].copy()\n",
    "\n",
    "            loop = asyncio.get_event_loop()\n",
    "            results, _, _ = await loop.run_in_executor(None, analyzer, img)\n",
    "            all_ocr_text = extract_text_preserving_layout(results)\n",
    "\n",
    "        return {\"result\": all_ocr_text}\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n",
    "\n",
    "if NGROK_AUTHTOKEN:\n",
    "    conf.get_default().auth_token = NGROK_AUTHTOKEN\n",
    "    conf.get_default().region = \"jp\"\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    try:\n",
    "        tunnel = ngrok.connect(8000)\n",
    "        public_url = tunnel.public_url\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"サーバーが起動しました\")\n",
    "        print(f\"公開URL: {public_url}\")\n",
    "        \n",
    "        print(\"\\n---------------------------------------------------------\")\n",
    "        print(\"   環境変数設定コマンド (コピーして実行してください)\")\n",
    "        print(\"---------------------------------------------------------\")\n",
    "\n",
    "        print(\"\\n【 Windows (PowerShell) 】\")\n",
    "        print(f'$env:OCR_API_URL = \"{public_url}\"')\n",
    "\n",
    "        print(\"\\n【 Windows (コマンドプロンプト) 】\")\n",
    "        print(f'set OCR_API_URL={public_url}')\n",
    "\n",
    "        print(\"\\n【 Ubuntu / Mac (Bash/Zsh) 】\")\n",
    "        print(f'export OCR_API_URL=\"{public_url}\"')\n",
    "        \n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "        config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n",
    "        server = uvicorn.Server(config)\n",
    "        await server.serve()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"起動エラー: {e}\")\n",
    "else:\n",
    "    print(\"NGROK_AUTHTOKEN が設定されていません。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
